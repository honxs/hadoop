<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">    <modelVersion>4.0.0</modelVersion>

    <groupId>cn.mastercom.bigdata</groupId>
    <artifactId>bigdata-hadoop-tools</artifactId>
    <version>1.0-SNAPSHOT</version>

    <repositories>
  
    <repository>  
        <id>maven-ali</id>  
        <url>http://maven.aliyun.com/nexus/content/groups/public//</url> 
        <releases>  
            <enabled>true</enabled>  
        </releases>  
        <snapshots>  
            <enabled>true</enabled>  
            <updatePolicy>always</updatePolicy>  
            <checksumPolicy>fail</checksumPolicy>  
        </snapshots>  
    </repository>  

        <repository>
            <id>maven-net-cn</id>
            <name>Maven China Mirror</name>
            <url>http://repo2.maven.org/maven2/</url>
            <releases>
                <enabled>true</enabled>
            </releases>
            <snapshots>
                <enabled>true</enabled>
            </snapshots>
        </repository>
        <repository>
            <id>for-ice-tar</id>
            <name>ebi</name>
            <url>http://www.ebi.ac.uk/intact/maven/nexus/content/repositories/ebi-repo/</url>
            <releases>
                <enabled>true</enabled>
            </releases>
            <snapshots>
                <enabled>true</enabled>
            </snapshots>
        </repository>
    </repositories>

    <properties>
        <hadoop-version>2.7.0</hadoop-version>
        <spark.version>1.5.2</spark.version>
        <scala.version>2.10</scala.version>
        <hbase.version>1.0.1.1</hbase.version>
        <zookepper.version>3.4.6</zookepper.version>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    </properties>

    <dependencies>
        <dependency>
            <groupId>cn.mastercom.bigdata</groupId>
            <artifactId>bigdata-common</artifactId>
            <version>1.0-SNAPSHOT</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-hdfs</artifactId>
            <version>${hadoop-version}</version>
            <exclusions>  
            <!-- 此处不要注释掉,因为spark调试会报错! 编译的时候没问题,运行的时候会jar包冲突  -->
       		 	 <exclusion>  
            		<groupId>javax.servlet</groupId>  
            		<artifactId>*</artifactId>  
        		</exclusion>
        		<!-- 已经有一个类来解析xml，再引入这个包会导致冲突 -->
       		 	<exclusion>
       		 		<groupId>xerces</groupId>
       		 		<artifactId>xercesImpl</artifactId>
       		 	</exclusion>
       		 	<!-- 已经有一个类来解析xml，再引入这个包会导致冲突 -->
       		 	<exclusion>
       		 		<groupId>xalan</groupId>
       		 		<artifactId>xalan</artifactId>
       		 	</exclusion>
            </exclusions>  
        </dependency>
		<dependency>
		    <groupId>xerces</groupId>
		    <artifactId>xercesImpl</artifactId>
		    <version>2.9.1</version>
		</dependency>
		<dependency>
		    <groupId>xalan</groupId>
		    <artifactId>xalan</artifactId>
		    <version>2.7.1</version>
		</dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-common</artifactId>
            <version>${hadoop-version}</version>
            <exclusions>  
       		 	<exclusion>  
            		<groupId>javax.servlet</groupId>  
            		<artifactId>*</artifactId>  
        		</exclusion>  
   			</exclusions>  
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-client</artifactId>
            <version>${hadoop-version}</version>
            <exclusions>  
       		 	<exclusion>  
            		<groupId>javax.servlet</groupId>  
            		<artifactId>*</artifactId>  
        		</exclusion>  
   			</exclusions>  
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-yarn-client</artifactId>
            <version>${hadoop-version}</version>
            <exclusions>  
       		 	<exclusion>  
            		<groupId>javax.servlet</groupId>  
            		<artifactId>*</artifactId>  
        		</exclusion>  
   			</exclusions>  
        </dependency>
        
		<dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_${scala.version}</artifactId>
            <version>${spark.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-sql_${scala.version}</artifactId>
            <version>${spark.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-hive_${scala.version}</artifactId>
            <version>${spark.version}</version>
        </dependency>

	<dependency>
		<groupId>org.apache.hbase</groupId>
		<artifactId>hbase</artifactId>
		<version>${hbase.version}</version>
		<type>pom</type>
	</dependency>
	
	<dependency>
    	<groupId>org.apache.hbase</groupId>
   		 <artifactId>hbase-client</artifactId>
  	 	 <version>${hbase.version}</version>
	</dependency>
        
    <dependency>
   	 	<groupId>org.apache.zookeeper</groupId>
   	 	<artifactId>zookeeper</artifactId>
  	  	<version>${zookepper.version}</version>
  	  	<type>pom</type>
	</dependency>
        
	<dependency>
		<groupId>jdk.tools</groupId>
		<artifactId>jdk.tools</artifactId>
		<version>1.6</version>
		<scope>system</scope>
		<systemPath>${JAVA_HOME}/lib/tools.jar</systemPath>
	</dependency>

		<dependency>
            <groupId>com.ice</groupId>
            <artifactId>tar</artifactId>
            <version>1.0</version>
        </dependency>
        
		<dependency>
            <groupId>dom4j</groupId>
            <artifactId>dom4j</artifactId>
            <version>1.6.1</version>
        </dependency>
		
		<dependency>
            <groupId>redis.clients</groupId>
            <artifactId>jedis</artifactId>
            <version>2.9.0</version>
            <type>jar</type>
            <scope>compile</scope>
   		</dependency>
    </dependencies>

<distributionManagement>
    <repository>
        <id>releases</id>
        <url>http://192.168.1.54:56789/repository/releases/</url>
    </repository>
    <snapshotRepository>
        <id>snapshots</id>
        <url>http://192.168.1.54:56789/repository/snapshots/</url>
    </snapshotRepository>
</distributionManagement>

    <build>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>3.2</version>
                <configuration>
                    <source>1.7</source> <!-- 源代码使用的开发版本 -->
                    <target>1.7</target> <!-- 需要生成的目标class文件的编译版本 -->
                    <!-- 一般而言，target与source是保持一致的，但是，有时候为了让程序能在其他版本的jdk中运行(对于低版本目标jdk，源代码中需要没有使用低版本jdk中不支持的语法)，会存在target不同于source的情况 -->

                    <!-- 这下面的是可选项 -->
                    <!-- <meminitial>128m</meminitial>-->
                    <!--<maxmem>512m</maxmem>-->
                    <!--<fork>true</fork>--> <!-- fork is enable,用于明确表示不同于默认的JDK去编译 -->
                    <!-- <compilerVersion>1.3</compilerVersion>-->

                    <!-- 这个选项用来传递编译器自身不包含但是却支持的参数选项 -->
                    <!--<compilerArgument>-verbose -bootclasspath ${java.home}\lib\rt.jar</compilerArgument>-->

                </configuration>
            </plugin>
        </plugins>
    </build>
</project>